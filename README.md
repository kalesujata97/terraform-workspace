# Terraform script to  setup the following tasks by using terraform remote backend:
	1.Setup a lambda that gets triggered on file upload to the the s3 bucket
	2.The lambda should read the uploaded CSV file(column names/data can be of your choice)
	and store itâ€™s content in to DynamoDB table
	3.Create an Authenticated(token based) Rest API endpoints that do CRUD on the records
	stored in DynamoDB after CSV file upload
	
Prerequisite: 
1. Need an aws account(free trial is sufficient) with access key and secret key (adminstratative access is needed).
2. Need a terraform cloud account to use a terraform remote backend.
3. Need a GitHub account
			  
Steps to run this terraform script:
1. Fork this git repository to your github account.
2. Create organization in terraform cloud.
3. Create new workspace, connect github, authorize it and  select your forked repository. Give name to workspace to create it.
	This step will create version control system (VCS) enabled workspace with GitHub. This will enable us to collaborate with our team on Terraform configurations.
4. Edit the main.tf file to specify your organization and workspace. 
5. Configure workspace variable.
   Under variables tag, scroll down to the "Environment Variables" section, and create two variables as
		1.AWS_ACCESS_KEY_ID with the Access key ID 
		2.AWS_SECRET_ACCESS_KEY with the Secret access key
   Check the "Sensitive" checkbox for both of these variables and click the "Save variable" button.

6. Now your workspace is configured, use the "Queue Plan" button to start a plan. Terraform Cloud will run a plan step, which creates a list of the requested changes. This may take a few minutes.
Once the plan is complete, you need to confirm it before you can apply it. Click the "Confirm & Apply" button to continue.


After performing above all steps, terraform will create aws services as required iam roles, s3 bucket, lambda function, add s3 trigger to lambda, dynamodb table,api-gateway.

Once above all services are created you can upload the Employee.csv file(present in git repo) to s3. We can add this upload step in terraform also but to test s3 trigger lambda function manually I am uploading the file to s3.
Once upload is done, you can check the dynamodb table items. There you can see the items from Employee.csv file.

Next, go to api-gateway. There you can see the DynamoAPI named API. Go to that API and just deploy it using default stage. wait for 2 minutes.
Take invoke url generated by stage and run it in your broweser as follows:
https://invoke-url/stage-name/empid (need to specify the employee id)
for ex. https://0ns9bg3gde.execute-api.us-east-2.amazonaws.com/default/1

You can see employee details returned.
